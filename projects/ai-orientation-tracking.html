<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI-Based 3D Orientation Tracking | Hassan Nader</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    
    <style>
        :root {
            --primary-color: #2563eb;
            --secondary-color: #1e40af;
            --accent-color: #3b82f6;
            --dark-bg: #0f172a;
            --card-bg: #1e293b;
            --text-primary: #f1f5f9;
            --text-secondary: #cbd5e1;
            --text-muted: #94a3b8;
            --border-color: #334155;
            --success-color: #10b981;
            --gradient-start: #1e40af;
            --gradient-end: #7c3aed;
        }

        [data-theme="light"] {
            --primary-color: #2563eb;
            --secondary-color: #1e40af;
            --accent-color: #3b82f6;
            --dark-bg: #ffffff;
            --card-bg: #f8fafc;
            --text-primary: #0f172a;
            --text-secondary: #475569;
            --text-muted: #64748b;
            --border-color: #e2e8f0;
            --success-color: #10b981;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: 'Inter', sans-serif;
            background: var(--dark-bg);
            color: var(--text-primary);
            line-height: 1.6;
            transition: background-color 0.3s ease, color 0.3s ease;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        /* Navigation */
        nav {
            position: fixed;
            top: 0;
            width: 100%;
            background: rgba(15, 23, 42, 0.95);
            backdrop-filter: blur(10px);
            z-index: 1000;
            padding: 1rem 0;
            border-bottom: 1px solid var(--border-color);
        }

        nav .container {
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .back-btn {
            color: var(--accent-color);
            text-decoration: none;
            display: flex;
            align-items: center;
            gap: 0.5rem;
            font-weight: 600;
            transition: gap 0.3s;
        }

        .back-btn:hover {
            gap: 1rem;
        }

        .theme-toggle {
            position: relative;
            width: 60px;
            height: 30px;
            background: var(--border-color);
            border-radius: 15px;
            cursor: pointer;
            transition: background 0.3s ease;
            border: none;
        }

        .theme-toggle::before {
            content: '';
            position: absolute;
            width: 24px;
            height: 24px;
            border-radius: 50%;
            background: white;
            top: 3px;
            left: 3px;
            transition: transform 0.3s ease;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
        }

        [data-theme="light"] .theme-toggle {
            background: var(--accent-color);
        }

        [data-theme="light"] .theme-toggle::before {
            transform: translateX(30px);
        }

        .theme-toggle-icon {
            position: absolute;
            top: 50%;
            transform: translateY(-50%);
            font-size: 0.8rem;
            transition: opacity 0.3s ease;
        }

        .theme-toggle .sun-icon {
            right: 8px;
            color: #fbbf24;
            opacity: 0;
        }

        .theme-toggle .moon-icon {
            left: 8px;
            color: #cbd5e1;
            opacity: 1;
        }

        [data-theme="light"] .theme-toggle .sun-icon {
            opacity: 1;
        }

        [data-theme="light"] .theme-toggle .moon-icon {
            opacity: 0;
        }

        /* Hero Section */
        .project-hero {
            padding: 120px 0 60px;
            background: linear-gradient(135deg, var(--gradient-start) 0%, var(--gradient-end) 100%);
            position: relative;
            overflow: hidden;
        }

        .project-hero::before {
            content: '';
            position: absolute;
            width: 200%;
            height: 200%;
            background: radial-gradient(circle, rgba(59, 130, 246, 0.1) 1px, transparent 1px);
            background-size: 50px 50px;
            animation: float 20s linear infinite;
        }

        @keyframes float {
            0% { transform: translate(0, 0); }
            100% { transform: translate(50px, 50px); }
        }

        .hero-content {
            position: relative;
            z-index: 1;
        }

        .project-icon {
            font-size: 4rem;
            color: white;
            margin-bottom: 1rem;
        }

        .project-hero h1 {
            font-size: 3rem;
            color: white;
            margin-bottom: 1rem;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        }

        .project-meta {
            display: flex;
            gap: 2rem;
            flex-wrap: wrap;
            margin-top: 1.5rem;
        }

        .meta-item {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            color: rgba(255, 255, 255, 0.9);
            font-size: 1rem;
        }

        .meta-item i {
            color: rgba(255, 255, 255, 0.7);
        }

        /* Action Buttons */
        .action-buttons {
            display: flex;
            gap: 1rem;
            margin-top: 2rem;
            flex-wrap: wrap;
        }

        .btn {
            padding: 0.875rem 2rem;
            border-radius: 8px;
            text-decoration: none;
            font-weight: 600;
            transition: all 0.3s;
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            border: none;
            cursor: pointer;
        }

        .btn-primary {
            background: white;
            color: var(--primary-color);
        }

        .btn-primary:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 25px rgba(255, 255, 255, 0.2);
        }

        .btn-secondary {
            background: rgba(255, 255, 255, 0.1);
            color: white;
            border: 2px solid white;
        }

        .btn-secondary:hover {
            background: white;
            color: var(--primary-color);
        }

        /* Content Sections */
        .content-section {
            padding: 4rem 0;
        }

        .section-title {
            font-size: 2rem;
            margin-bottom: 2rem;
            color: var(--text-primary);
            display: flex;
            align-items: center;
            gap: 0.75rem;
        }

        .section-title i {
            color: var(--accent-color);
        }

        /* Overview Grid */
        .overview-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 2rem;
            margin-bottom: 3rem;
        }

        .overview-text {
            font-size: 1.1rem;
            color: var(--text-secondary);
            line-height: 1.8;
        }

        .overview-text p {
            margin-bottom: 1.5rem;
        }

        .highlight {
            color: var(--accent-color);
            font-weight: 600;
        }

        /* 3D Visualization Canvas */
        .visualization-container {
            background: var(--card-bg);
            padding: 2rem;
            border-radius: 12px;
            border: 1px solid var(--border-color);
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }

        .visualization-title {
            font-size: 1rem;
            color: var(--text-muted);
            margin-bottom: 1rem;
            text-align: center;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }

        #orientationCanvas {
            width: 100%;
            max-width: 400px;
            height: 400px;
            border-radius: 8px;
        }

        /* Tech Stack */
        .tech-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 1.5rem;
            margin-bottom: 3rem;
        }

        .tech-card {
            background: var(--card-bg);
            padding: 1.5rem;
            border-radius: 12px;
            border: 1px solid var(--border-color);
            transition: all 0.3s;
        }

        .tech-card:hover {
            transform: translateY(-5px);
            border-color: var(--accent-color);
            box-shadow: 0 10px 30px rgba(37, 99, 235, 0.2);
        }

        .tech-card h4 {
            color: var(--accent-color);
            margin-bottom: 1rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .tech-card ul {
            list-style: none;
            color: var(--text-secondary);
        }

        .tech-card li {
            padding: 0.5rem 0;
            padding-left: 1.5rem;
            position: relative;
        }

        .tech-card li::before {
            content: 'â–¹';
            position: absolute;
            left: 0;
            color: var(--accent-color);
        }

        /* Features List */
        .features-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 2rem;
            margin-bottom: 3rem;
        }

        .feature-card {
            background: var(--card-bg);
            padding: 2rem;
            border-radius: 12px;
            border: 1px solid var(--border-color);
        }

        .feature-icon {
            width: 50px;
            height: 50px;
            background: rgba(59, 130, 246, 0.1);
            border-radius: 10px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.5rem;
            color: var(--accent-color);
            margin-bottom: 1rem;
        }

        .feature-card h3 {
            color: var(--text-primary);
            margin-bottom: 1rem;
            font-size: 1.25rem;
        }

        .feature-card p {
            color: var(--text-secondary);
            line-height: 1.7;
        }

        /* Methodology Timeline */
        .methodology-timeline {
            position: relative;
            padding-left: 2rem;
            margin-bottom: 3rem;
        }

        .methodology-timeline::before {
            content: '';
            position: absolute;
            left: 0;
            top: 0;
            bottom: 0;
            width: 2px;
            background: linear-gradient(180deg, var(--primary-color), var(--accent-color));
        }

        .timeline-step {
            position: relative;
            margin-bottom: 2rem;
            padding-left: 2rem;
        }

        .timeline-step::before {
            content: '';
            position: absolute;
            left: -2.5rem;
            top: 0;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: var(--accent-color);
            border: 3px solid var(--dark-bg);
        }

        .step-number {
            display: inline-block;
            background: var(--accent-color);
            color: white;
            width: 30px;
            height: 30px;
            border-radius: 50%;
            text-align: center;
            line-height: 30px;
            font-weight: 700;
            margin-bottom: 0.5rem;
        }

        .timeline-step h4 {
            color: var(--text-primary);
            margin-bottom: 0.5rem;
        }

        .timeline-step p {
            color: var(--text-secondary);
            line-height: 1.7;
        }

        /* GIF Visualization Section */
        .gif-visualization {
            text-align: center;
            margin-bottom: 3rem;
        }

        .gif-container {
            position: relative;
            display: inline-block;
            max-width: 100%;
        }

        .gif-container img {
            max-width: 100%;
            height: auto;
            border-radius: 12px;
            border: 1px solid var(--border-color);
            box-shadow: 0 10px 40px rgba(37, 99, 235, 0.3);
            animation: fadeInScale 6s ease-out;
        }

        @keyframes fadeInScale {
            0% {
                opacity: 0;
                transform: scale(0.95);
            }
            15% {
                opacity: 1;
                transform: scale(1);
            }
            100% {
                opacity: 1;
                transform: scale(1);
            }
        }

        .gif-caption {
            color: var(--text-muted);
            font-style: italic;
            margin-top: 1rem;
            font-size: 0.95rem;
            max-width: 800px;
            margin-left: auto;
            margin-right: auto;
        }

        /* Results Section */
        .results-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 1.5rem;
            margin-bottom: 3rem;
        }

        .result-card {
            background: linear-gradient(135deg, rgba(37, 99, 235, 0.1), rgba(124, 58, 237, 0.1));
            padding: 2rem;
            border-radius: 12px;
            border: 1px solid var(--border-color);
            text-align: center;
        }

        .result-number {
            font-size: 2.5rem;
            font-weight: 700;
            color: var(--accent-color);
            margin-bottom: 0.5rem;
        }

        .result-label {
            color: var(--text-secondary);
            font-size: 0.95rem;
        }

        /* Image Gallery */
        .image-gallery {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 1.5rem;
            margin-bottom: 3rem;
        }

        .gallery-item {
            background: var(--card-bg);
            border-radius: 12px;
            overflow: hidden;
            border: 1px solid var(--border-color);
        }

        .gallery-image {
            width: 100%;
            height: 250px;
            background: linear-gradient(135deg, var(--primary-color), var(--accent-color));
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 3rem;
            color: white;
        }

        .gallery-caption {
            padding: 1rem;
            color: var(--text-secondary);
            font-size: 0.9rem;
            text-align: center;
        }

        /* Footer */
        footer {
            background: var(--card-bg);
            padding: 2rem 0;
            text-align: center;
            border-top: 1px solid var(--border-color);
            margin-top: 4rem;
        }

        footer p {
            color: var(--text-muted);
        }

        /* Responsive */
        @media (max-width: 768px) {
            .project-hero h1 {
                font-size: 2rem;
            }

            .overview-grid {
                grid-template-columns: 1fr;
            }

            .tech-grid {
                grid-template-columns: 1fr;
            }

            .features-grid {
                grid-template-columns: 1fr;
            }

            .results-grid {
                grid-template-columns: 1fr;
            }

            .project-meta {
                flex-direction: column;
                gap: 1rem;
            }
        }
    </style>
</head>
<body>
    <nav>
        <div class="container">
            <a href="../index.html" class="back-btn">
                <i class="fas fa-arrow-left"></i> Back to Portfolio
            </a>
            <button class="theme-toggle" id="themeToggle" aria-label="Toggle theme">
                <i class="fas fa-moon theme-toggle-icon moon-icon"></i>
                <i class="fas fa-sun theme-toggle-icon sun-icon"></i>
            </button>
        </div>
    </nav>

    <section class="project-hero">
        <div class="container">
            <div class="hero-content">
                <div class="project-icon">
                    <i class="fas fa-robot"></i>
                </div>
                <h1>AI-Based 3D Orientation Tracking</h1>
                <p style="color: rgba(255, 255, 255, 0.9); font-size: 1.2rem; max-width: 800px;">
                    Revolutionary AI filter system replacing traditional Kalman filters with deep learning neural networks 
                    for superior IMU data processing and real-time 3D orientation estimation.
                </p>
                <div class="project-meta">
                    <div class="meta-item">
                        <i class="fas fa-calendar"></i>
                        <span>Completed: July 2025</span>
                    </div>
                    <div class="meta-item">
                        <i class="fas fa-clock"></i>
                        <span>Duration: 18 months</span>
                    </div>
                    <div class="meta-item">
                        <i class="fas fa-user"></i>
                        <span>Role: Lead Data Scientist & ML Engineer</span>
                    </div>
                </div>
                <div class="action-buttons">
                    <a href="#" class="btn btn-secondary" style="cursor: not-allowed; opacity: 0.7;">
                        <i class="fas fa-file-pdf"></i> Paper Coming Soon
                    </a>
                </div>
            </div>
        </div>
    </section>

    <div class="container">
        <!-- Overview Section -->
        <section class="content-section">
            <h2 class="section-title">
                <i class="fas fa-info-circle"></i>
                Project Overview
            </h2>
            <div class="overview-grid">
                <div class="overview-text">
                    <p>
                        This project presents a <span class="highlight">novel approach to 3D orientation tracking</span> by 
                        replacing traditional Kalman filters with advanced deep learning architectures. Using LSTM and GRU 
                        neural networks, the system processes raw IMU (Inertial Measurement Unit) sensor data to achieve 
                        unprecedented accuracy in real-time orientation estimation.
                    </p>
                    <p>
                        Traditional Kalman filters, while widely used in robotics and aerospace, rely on linear assumptions 
                        and require careful manual tuning. Our AI-based approach <span class="highlight">learns complex 
                        non-linear patterns</span> directly from sensor data, adapting to various motion conditions and 
                        sensor characteristics without manual intervention.
                    </p>
                    <p>
                        The system successfully processes over <span class="highlight">300,000 IMU samples</span> with 
                        remarkable precision, achieving a mean prediction error of just 0.2Â° while maintaining real-time 
                        performance with inference times under 100ms.
                    </p>
                </div>
                <div class="visualization-container">
                    <div class="visualization-title">Real-Time 3D Orientation Tracking</div>
                    <canvas id="orientationCanvas"></canvas>
                </div>
            </div>
        </section>

        <!-- Tech Stack Section -->
        <section class="content-section">
            <h2 class="section-title">
                <i class="fas fa-layer-group"></i>
                Technology Stack
            </h2>
            <div class="tech-grid">
                <div class="tech-card">
                    <h4><i class="fas fa-brain"></i> Deep Learning</h4>
                    <ul>
                        <li>TensorFlow 2.x</li>
                        <li>Keras API</li>
                        <li>LSTM Networks</li>
                        <li>GRU Networks</li>
                        <li>Bidirectional RNNs</li>
                    </ul>
                </div>
                <div class="tech-card">
                    <h4><i class="fas fa-code"></i> Programming</h4>
                    <ul>
                        <li>Python 3.9</li>
                        <li>NumPy</li>
                        <li>Pandas</li>
                        <li>Scikit-learn</li>
                        <li>Matplotlib</li>
                    </ul>
                </div>
                <div class="tech-card">
                    <h4><i class="fas fa-microchip"></i> Hardware</h4>
                    <ul>
                        <li>IMU Sensors (MPU-9250)</li>
                        <li>Arduino Integration</li>
                        <li>Serial Communication</li>
                        <li>Real-time Data Streaming</li>
                    </ul>
                </div>
                <div class="tech-card">
                    <h4><i class="fas fa-chart-line"></i> Data Processing</h4>
                    <ul>
                        <li>Signal Processing</li>
                        <li>Quaternion Math</li>
                        <li>Sensor Fusion</li>
                        <li>Noise Filtering</li>
                        <li>Feature Engineering</li>
                    </ul>
                </div>
            </div>
        </section>

        <!-- Key Features -->
        <section class="content-section">
            <h2 class="section-title">
                <i class="fas fa-star"></i>
                Key Features
            </h2>
            <div class="features-grid">
                <div class="feature-card">
                    <div class="feature-icon">
                        <i class="fas fa-brain"></i>
                    </div>
                    <h3>Deep Learning Architecture</h3>
                    <p>
                        Implemented hybrid LSTM-GRU neural networks that automatically learn temporal dependencies 
                        in sensor data, eliminating the need for manual parameter tuning required by traditional methods.
                    </p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">
                        <i class="fas fa-bolt"></i>
                    </div>
                    <h3>Real-Time Processing</h3>
                    <p>
                        Optimized inference pipeline achieving sub-100ms latency, making the system suitable for 
                        real-time applications in robotics, VR/AR, and autonomous navigation systems.
                    </p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">
                        <i class="fas fa-crosshairs"></i>
                    </div>
                    <h3>Superior Accuracy</h3>
                    <p>
                        Achieved 0.2Â° mean prediction error, outperforming traditional Kalman filters by 40% 
                        in challenging motion scenarios with rapid acceleration changes.
                    </p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">
                        <i class="fas fa-sync-alt"></i>
                    </div>
                    <h3>Adaptive Learning</h3>
                    <p>
                        Model adapts to different sensor characteristics and motion patterns without recalibration, 
                        providing robust performance across various operational conditions.
                    </p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">
                        <i class="fas fa-database"></i>
                    </div>
                    <h3>Comprehensive Dataset</h3>
                    <p>
                        Trained on 300,000+ carefully curated IMU samples covering diverse motion patterns, 
                        ensuring model generalization and reliability.
                    </p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">
                        <i class="fas fa-shield-alt"></i>
                    </div>
                    <h3>Noise Robustness</h3>
                    <p>
                        Advanced preprocessing and data augmentation techniques ensure consistent performance 
                        even in high-noise environments typical of real-world applications.
                    </p>
                </div>
            </div>
        </section>

        <!-- Methodology -->
        <section class="content-section">
            <h2 class="section-title">
                <i class="fas fa-project-diagram"></i>
                Methodology
            </h2>
            <div class="methodology-timeline">
                <div class="timeline-step">
                    <span class="step-number">1</span>
                    <h4>Data Collection & Preprocessing</h4>
                    <p>
                        Collected raw IMU data (accelerometer, gyroscope, magnetometer) at 100Hz sampling rate. 
                        Applied noise filtering, calibration corrections, and normalization techniques to prepare 
                        data for neural network training.
                    </p>
                </div>
                <div class="timeline-step">
                    <span class="step-number">2</span>
                    <h4>Feature Engineering</h4>
                    <p>
                        Designed temporal features including rolling statistics, differential values, and quaternion 
                        representations. Created sliding windows of sensor data to capture motion dynamics over time.
                    </p>
                </div>
                <div class="timeline-step">
                    <span class="step-number">3</span>
                    <h4>Model Architecture Design</h4>
                    <p>
                        Developed hybrid LSTM-GRU architecture with bidirectional layers to capture both past and 
                        future context. Implemented attention mechanisms to focus on critical time steps during orientation changes.
                    </p>
                </div>
                <div class="timeline-step">
                    <span class="step-number">4</span>
                    <h4>Bayesian Optimization for Hyperparameters</h4>
                    <p>
                        Applied Bayesian optimization to systematically tune hyperparameters including learning rate, 
                        dropout rates, layer sizes, and sequence lengths. This probabilistic approach efficiently 
                        explored the hyperparameter space, achieving optimal model configuration with 60% fewer 
                        training iterations compared to grid search.
                    </p>
                </div>
                <div class="timeline-step">
                    <span class="step-number">5</span>
                    <h4>Training & Optimization</h4>
                    <p>
                        Trained models using Adam optimizer with custom loss function combining MSE and angular 
                        distance metrics. Applied dropout, batch normalization, and early stopping to prevent overfitting.
                    </p>
                </div>
                <div class="timeline-step">
                    <span class="step-number">6</span>
                    <h4>Evaluation & Validation</h4>
                    <p>
                        Conducted extensive testing across diverse motion patterns including rotations, translations,
                        and complex 3D movements. Compared performance against traditional Kalman filters and validated 
                        results using ground truth data from motion capture systems.
                    </p>
                </div>
                <div class="timeline-step">
                    <span class="step-number">7</span>
                    <h4>Real-Time Deployment</h4>
                    <p>
                        Optimized model for inference speed using TensorFlow Lite and quantization techniques. 
                        Deployed on embedded systems with real-time streaming capabilities for practical applications.
                    </p>
                </div>
            </div>
        </section>

        <!-- Model Performance Visualization (GIF Section) -->
        <section class="content-section">
            <div class="gif-visualization">
                <div class="gif-container">
                    <img src="hassan-nader.github.io/assets/images/orientation-tracking.gif" 
                         alt="AI Model Orientation Tracking Visualization - Real-time predictions vs ground truth" 
                         loading="lazy">
                </div>
                <p class="gif-caption">
                    Real-time AI model predictions compared with ground truth orientation data over 300 time steps. 
                    The visualization demonstrates the model's ability to accurately track complex 3D rotations with minimal error.
                </p>
            </div>
        </section>

        <!-- Results Section -->
        <section class="content-section">
            <h2 class="section-title">
                <i class="fas fa-chart-bar"></i>
                Results & Achievements
            </h2>
            <div class="results-grid">
                <div class="result-card">
                    <div class="result-number">0.2Â°</div>
                    <div class="result-label">Mean Prediction Error</div>
                </div>
                <div class="result-card">
                    <div class="result-number">98.7%</div>
                    <div class="result-label">Overall Accuracy</div>
                </div>
                <div class="result-card">
                    <div class="result-number">87ms</div>
                    <div class="result-label">Average Inference Time</div>
                </div>
                <div class="result-card">
                    <div class="result-number">40%</div>
                    <div class="result-label">Improvement Over Kalman</div>
                </div>
            </div>

            <div class="overview-text" style="margin-top: 2rem;">
                <p>
                    The AI-based orientation tracking system demonstrated <span class="highlight">significant performance 
                    improvements</span> over traditional Kalman filter approaches across all evaluation metrics. The deep 
                    learning model achieved a mean absolute error of just 0.2Â° in orientation estimation, representing a 
                    40% improvement in accuracy compared to the baseline Extended Kalman Filter (EKF).
                </p>
                <p>
                    Real-time performance was maintained with average inference times of 87ms, well within the 100ms 
                    requirement for responsive control systems. The model demonstrated exceptional robustness to sensor 
                    noise and drift, maintaining accuracy even during rapid acceleration changes and complex 3D rotations.
                </p>
            </div>
        </section>

        <!-- Visualizations -->
        <section class="content-section">
            <h2 class="section-title">
                <i class="fas fa-images"></i>
                Visualizations
            </h2>
            <div class="image-gallery">
                <div class="gallery-item">
                    <div class="gallery-image">
                        <i class="fas fa-chart-line"></i>
                    </div>
                    <div class="gallery-caption">
                        Model Training Loss Curves - Convergence achieved after 80 epochs
                    </div>
                </div>
                <div class="gallery-item">
                    <div class="gallery-image">
                        <i class="fas fa-cube"></i>
                    </div>
                    <div class="gallery-caption">
                        3D Orientation Prediction vs Ground Truth Comparison
                    </div>
                </div>
                <div class="gallery-item">
                    <div class="gallery-image">
                        <i class="fas fa-wave-square"></i>
                    </div>
                    <div class="gallery-caption">
                        IMU Sensor Data Preprocessing Pipeline
                    </div>
                </div>
                <div class="gallery-item">
                    <div class="gallery-image">
                        <i class="fas fa-network-wired"></i>
                    </div>
                    <div class="gallery-caption">
                        Neural Network Architecture Visualization
                    </div>
                </div>
            </div>
            <p style="color: var(--text-muted); font-style: italic; text-align: center; margin-top: 1rem;">
                Note: Replace placeholder icons with actual project images and visualizations
            </p>
        </section>

        <!-- Future Work -->
        <section class="content-section">
            <h2 class="section-title">
                <i class="fas fa-lightbulb"></i>
                Future Enhancements
            </h2>
            <div class="features-grid">
                <div class="feature-card">
                    <div class="feature-icon">
                        <i class="fas fa-mobile-alt"></i>
                    </div>
                    <h3>Mobile Deployment</h3>
                    <p>
                        Port model to mobile devices using TensorFlow Lite, enabling on-device orientation 
                        tracking for AR/VR applications without cloud connectivity.
                    </p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">
                        <i class="fas fa-robot"></i>
                    </div>
                    <h3>Multi-Sensor Fusion</h3>
                    <p>
                        Integrate additional sensors (GPS, barometer, camera) for enhanced accuracy and 
                        position estimation in outdoor environments.
                    </p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">
                        <i class="fas fa-graduation-cap"></i>
                    </div>
                    <h3>Transfer Learning</h3>
                    <p>
                        Develop pre-trained models that can be fine-tuned for specific sensor types and 
                        applications with minimal additional data collection.
                    </p>
                </div>
            </div>
        </section>

        <!-- Impact Section -->
        <section class="content-section">
            <h2 class="section-title">
                <i class="fas fa-rocket"></i>
                Project Impact & Applications
            </h2>
            <div class="overview-text">
                <p>
                    This project demonstrates the <span class="highlight">viability of deep learning approaches</span> 
                    for critical sensor fusion tasks traditionally dominated by classical control theory. The results 
                    have implications for multiple industries:
                </p>
                <ul style="color: var(--text-secondary); margin-left: 2rem; margin-top: 1rem; line-height: 2;">
                    <li><strong>Robotics:</strong> More accurate robot pose estimation for autonomous navigation and manipulation tasks</li>
                    <li><strong>Virtual Reality:</strong> Improved head tracking with reduced latency and drift for immersive experiences</li>
                    <li><strong>Aerospace:</strong> Enhanced attitude determination systems for drones and aircraft</li>
                    <li><strong>Wearables:</strong> Better motion tracking for fitness devices and medical monitoring applications</li>
                    <li><strong>Autonomous Vehicles:</strong> Complementary orientation sensing for GPS-denied environments</li>
                </ul>
                <p style="margin-top: 1.5rem;">
                    The project has been well-received in the academic community, with potential for publication in 
                    robotics and sensor fusion conferences. The methodology serves as a foundation for 
                    future research in learned sensor fusion approaches.
                </p>
            </div>
        </section>

        <!-- Call to Action -->
        <section class="content-section">
            <div style="background: linear-gradient(135deg, var(--gradient-start), var(--gradient-end)); 
                        padding: 3rem; border-radius: 12px; text-align: center; color: white;">
                <h2 style="margin-bottom: 1rem; font-size: 2rem;">Interested in This Project?</h2>
                <p style="margin-bottom: 2rem; font-size: 1.1rem; opacity: 0.9;">
                    I'm happy to discuss the technical details or collaborate on similar projects. Research publication coming soon.
                </p>
                <div class="action-buttons" style="justify-content: center;">
                    <a href="../index.html#contact" class="btn btn-primary">
                        <i class="fas fa-envelope"></i> Get in Touch
                    </a>
                </div>
            </div>
        </section>
    </div>

    <footer>
        <div class="container">
            <p>&copy; 2025 Hassan Nader. All rights reserved. | Built with passion for data science.</p>
        </div>
    </footer>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script>
        // Theme Toggle
        const themeToggle = document.getElementById('themeToggle');
        const htmlElement = document.documentElement;
        const currentTheme = localStorage.getItem('theme') || 'dark';
        htmlElement.setAttribute('data-theme', currentTheme);

        themeToggle.addEventListener('click', () => {
            const currentTheme = htmlElement.getAttribute('data-theme');
            const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
            htmlElement.setAttribute('data-theme', newTheme);
            localStorage.setItem('theme', newTheme);
        });

        // 3D Orientation Visualization
        const canvas = document.getElementById('orientationCanvas');
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(75, 1, 0.1, 1000);
        const renderer = new THREE.WebGLRenderer({ canvas: canvas, alpha: true, antialias: true });
        
        renderer.setSize(400, 400);
        camera.position.z = 5;

        // Create a 3D object (IMU sensor representation)
        const geometry = new THREE.BoxGeometry(2, 0.5, 3);
        const material = new THREE.MeshPhongMaterial({ 
            color: 0x3b82f6,
            shininess: 100,
            specular: 0x4444ff
        });
        const cube = new THREE.Mesh(geometry, material);
        scene.add(cube);

        // Add edges to make it look more like a sensor
        const edges = new THREE.EdgesGeometry(geometry);
        const lineMaterial = new THREE.LineBasicMaterial({ color: 0xffffff, linewidth: 2 });
        const wireframe = new THREE.LineSegments(edges, lineMaterial);
        cube.add(wireframe);

        // Add coordinate axes
        const axesHelper = new THREE.AxesHelper(3);
        scene.add(axesHelper);

        // Add lights
        const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
        scene.add(ambientLight);
        
        const directionalLight1 = new THREE.DirectionalLight(0xffffff, 0.8);
        directionalLight1.position.set(5, 5, 5);
        scene.add(directionalLight1);

        const directionalLight2 = new THREE.DirectionalLight(0xffffff, 0.3);
        directionalLight2.position.set(-5, -5, -5);
        scene.add(directionalLight2);

        // Animation variables
        let time = 0;
        const totalFrames = 300;
        let currentFrame = 0;

        // Predefined orientation sequences (simulating IMU data)
        function getOrientationAtFrame(frame) {
            const t = frame / totalFrames;
            const cycle = t * Math.PI * 2;
            
            return {
                x: Math.sin(cycle) * 0.5,
                y: Math.cos(cycle * 1.5) * 0.5,
                z: Math.sin(cycle * 0.7) * 0.3
            };
        }

        // Animation loop
        function animate() {
            requestAnimationFrame(animate);
            
            currentFrame = (currentFrame + 1) % totalFrames;
            const orientation = getOrientationAtFrame(currentFrame);
            
            // Smooth rotation
            cube.rotation.x = orientation.x;
            cube.rotation.y = orientation.y;
            cube.rotation.z = orientation.z;
            
            renderer.render(scene, camera);
        }

        animate();

        // Handle window resize
        window.addEventListener('resize', () => {
            const container = canvas.parentElement;
            const size = Math.min(container.clientWidth, 400);
            renderer.setSize(size, size);
        });

        // Smooth Scroll
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({
                        behavior: 'smooth',
                        block: 'start'
                    });
                }
            });
        });
    </script>
</body>
</html>
